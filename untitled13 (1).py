# -*- coding: utf-8 -*-
"""Untitled13.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1VgY65cKoWDMLZ8igGrxOW_95wtX-_zkY
"""

import nltk
from nltk.tokenize import word_tokenize
from nltk.util import ngrams
from nltk.probability import FreqDist

nltk.download('punkt')
nltk.download('punkt_tab') # Added to resolve LookupError

# Sample text
text = "Language modeling is an important part of natural language processing"

# Tokenize words
tokens = word_tokenize(text.lower())

# Create bigrams
bigrams = list(ngrams(tokens, 2))

# Frequency distribution
freq = FreqDist(bigrams)

print("Bigram Frequencies:")
for k, v in freq.items():
    print(k, ":", v)

print("\nMost Common Bigrams:")
print(freq.most_common(5))

import nltk
nltk.download('punkt')
nltk.download('punkt_tab') # Added to prevent future LookupError

from nltk.tokenize import word_tokenize
from nltk.util import ngrams
from nltk.probability import FreqDist

text = "Natural language processing enables machines to understand human language"

# Tokenization
tokens = word_tokenize(text.lower())

# Unigrams, Bigrams, Trigrams
unigrams = tokens
bigrams = list(ngrams(tokens, 2))
trigrams = list(ngrams(tokens, 3))

print("Unigrams:", unigrams)
print("Bigrams:", bigrams)
print("Trigrams:", trigrams)

# Most Common
print("\nMost Common Unigrams:")
print(FreqDist(unigrams).most_common(5))

print("\nMost Common Bigrams:")
print(FreqDist(bigrams).most_common(5))

print("\nMost Common Trigrams:")
print(FreqDist(trigrams).most_common(5))